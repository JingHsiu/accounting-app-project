package main

import (
	"encoding/json"
	"fmt"
	"go/ast"
	"go/parser"
	"go/token"
	"io/fs"
	"os"
	"path/filepath"
	"regexp"
	"strings"
	"time"
)

// DocumentationAgent æ™ºèƒ½æ–‡æª”è¿½è¹¤ AI Agent
type DocumentationAgent struct {
	projectRoot string
	config      *AgentConfig
	scanner     *CodeScanner
	analyzer    *FeatureAnalyzer
	updater     *DocUpdater
}

// AgentConfig Agent é…ç½®
type AgentConfig struct {
	MonitorPaths []string `json:"monitor_paths"`
	IgnorePaths  []string `json:"ignore_paths"`
	OutputFormat string   `json:"output_format"`
	UpdateDocs   bool     `json:"update_docs"`
}

// CodeScanner ç¨‹å¼ç¢¼æƒæå™¨
type CodeScanner struct {
	fileSet *token.FileSet
}

// FeatureAnalyzer åŠŸèƒ½åˆ†æå™¨
type FeatureAnalyzer struct {
	apiEndpoints  []APIEndpoint
	domainModels  []DomainModel
	useCases      []UseCase
	dbChanges     []DBChange
}

// DocUpdater æ–‡æª”æ›´æ–°å™¨
type DocUpdater struct {
	claudeFile   string
	statusFile   string
	readmeFile   string
}

// APIEndpoint API ç«¯é»è³‡è¨Š
type APIEndpoint struct {
	Method      string    `json:"method"`
	Path        string    `json:"path"`
	Handler     string    `json:"handler"`
	Controller  string    `json:"controller"`
	Description string    `json:"description"`
	File        string    `json:"file"`
	Line        int       `json:"line"`
	CreatedAt   time.Time `json:"created_at"`
}

// DomainModel é ˜åŸŸæ¨¡å‹è³‡è¨Š
type DomainModel struct {
	Name        string            `json:"name"`
	Type        string            `json:"type"` // Aggregate, Entity, ValueObject
	Fields      []ModelField      `json:"fields"`
	Methods     []string          `json:"methods"`
	File        string            `json:"file"`
	Description string            `json:"description"`
	CreatedAt   time.Time         `json:"created_at"`
}

// ModelField æ¨¡å‹æ¬„ä½
type ModelField struct {
	Name string `json:"name"`
	Type string `json:"type"`
	Tags string `json:"tags"`
}

// UseCase ä½¿ç”¨æ¡ˆä¾‹è³‡è¨Š
type UseCase struct {
	Name        string    `json:"name"`
	Type        string    `json:"type"` // Command, Query
	Service     string    `json:"service"`
	Methods     []string  `json:"methods"`
	File        string    `json:"file"`
	Description string    `json:"description"`
	CreatedAt   time.Time `json:"created_at"`
}

// DBChange è³‡æ–™åº«è®Šæ›´è³‡è¨Š
type DBChange struct {
	Type        string    `json:"type"` // CREATE_TABLE, ALTER_TABLE, etc
	Table       string    `json:"table"`
	Changes     string    `json:"changes"`
	File        string    `json:"file"`
	CreatedAt   time.Time `json:"created_at"`
}

// AnalysisResult åˆ†æçµæœ
type AnalysisResult struct {
	Timestamp    time.Time     `json:"timestamp"`
	FilesScanned int           `json:"files_scanned"`
	APIEndpoints []APIEndpoint `json:"api_endpoints"`
	DomainModels []DomainModel `json:"domain_models"`
	UseCases     []UseCase     `json:"use_cases"`
	DBChanges    []DBChange    `json:"db_changes"`
	Summary      string        `json:"summary"`
}

// NewDocumentationAgent å»ºç«‹æ–°çš„ Documentation Agent
func NewDocumentationAgent(projectRoot string) *DocumentationAgent {
	config := &AgentConfig{
		MonitorPaths: []string{
			"internal/accounting/adapter/controller",
			"internal/accounting/application/command",
			"internal/accounting/application/query",
			"internal/accounting/domain/model",
			"internal/accounting/frameworks/database",
		},
		IgnorePaths: []string{
			"*_test.go",
			"mock_*.go",
			"vendor/",
		},
		OutputFormat: "json",
		UpdateDocs:   true,
	}

	return &DocumentationAgent{
		projectRoot: projectRoot,
		config:      config,
		scanner:     &CodeScanner{fileSet: token.NewFileSet()},
		analyzer:    &FeatureAnalyzer{},
		updater: &DocUpdater{
			claudeFile: filepath.Join(projectRoot, "CLAUDE.md"),
			statusFile: filepath.Join(projectRoot, "docs", "PROJECT-STATUS.md"),
			readmeFile: filepath.Join(projectRoot, "README.md"),
		},
	}
}

// AnalyzeProject åˆ†ææ•´å€‹å°ˆæ¡ˆ
func (agent *DocumentationAgent) AnalyzeProject() (*AnalysisResult, error) {
	fmt.Println("ğŸ” é–‹å§‹åˆ†æå°ˆæ¡ˆ...")

	result := &AnalysisResult{
		Timestamp: time.Now(),
	}

	// é‡ç½®åˆ†æå™¨
	agent.analyzer = &FeatureAnalyzer{}

	// æƒææ‰€æœ‰ç›£æ§è·¯å¾‘
	for _, monitorPath := range agent.config.MonitorPaths {
		fullPath := filepath.Join(agent.projectRoot, monitorPath)
		if _, err := os.Stat(fullPath); os.IsNotExist(err) {
			continue
		}

		err := filepath.WalkDir(fullPath, func(path string, d fs.DirEntry, err error) error {
			if err != nil {
				return err
			}

			if d.IsDir() || !strings.HasSuffix(path, ".go") {
				return nil
			}

			// æª¢æŸ¥æ˜¯å¦è¦å¿½ç•¥
			if agent.shouldIgnoreFile(path) {
				return nil
			}

			return agent.analyzeFile(path)
		})

		if err != nil {
			fmt.Printf("âŒ æƒæè·¯å¾‘ %s æ™‚ç™¼ç”ŸéŒ¯èª¤: %v\n", fullPath, err)
		}
	}

	// æ•´åˆåˆ†æçµæœ
	result.APIEndpoints = agent.analyzer.apiEndpoints
	result.DomainModels = agent.analyzer.domainModels
	result.UseCases = agent.analyzer.useCases
	result.DBChanges = agent.analyzer.dbChanges
	result.FilesScanned = len(agent.analyzer.apiEndpoints) + len(agent.analyzer.domainModels) + len(agent.analyzer.useCases)

	// ç”Ÿæˆæ‘˜è¦
	result.Summary = agent.generateSummary(result)

	fmt.Printf("âœ… åˆ†æå®Œæˆ! æƒæäº† %d å€‹æª”æ¡ˆ\n", result.FilesScanned)
	fmt.Printf("   - ç™¼ç¾ %d å€‹ API ç«¯é»\n", len(result.APIEndpoints))
	fmt.Printf("   - ç™¼ç¾ %d å€‹ Domain Models\n", len(result.DomainModels))
	fmt.Printf("   - ç™¼ç¾ %d å€‹ Use Cases\n", len(result.UseCases))

	return result, nil
}

// shouldIgnoreFile æª¢æŸ¥æ˜¯å¦æ‡‰è©²å¿½ç•¥æª”æ¡ˆ
func (agent *DocumentationAgent) shouldIgnoreFile(path string) bool {
	for _, ignorePattern := range agent.config.IgnorePaths {
		if matched, _ := filepath.Match(ignorePattern, filepath.Base(path)); matched {
			return true
		}
	}
	return false
}

// analyzeFile åˆ†æå–®å€‹æª”æ¡ˆ
func (agent *DocumentationAgent) analyzeFile(filePath string) error {
	// è§£æ Go æª”æ¡ˆ
	src, err := os.ReadFile(filePath)
	if err != nil {
		return err
	}

	file, err := parser.ParseFile(agent.scanner.fileSet, filePath, src, parser.ParseComments)
	if err != nil {
		return err
	}

	// æ ¹æ“šæª”æ¡ˆé¡å‹é€²è¡Œä¸åŒçš„åˆ†æ
	relativePath := strings.TrimPrefix(filePath, agent.projectRoot+"/")
	
	switch {
	case strings.Contains(relativePath, "controller"):
		agent.analyzeController(file, relativePath)
	case strings.Contains(relativePath, "model"):
		agent.analyzeDomainModel(file, relativePath)
	case strings.Contains(relativePath, "command") || strings.Contains(relativePath, "query"):
		agent.analyzeUseCase(file, relativePath)
	case strings.Contains(relativePath, "schema.sql"):
		agent.analyzeDBSchema(filePath)
	}

	return nil
}

// analyzeController åˆ†ææ§åˆ¶å™¨æª”æ¡ˆ
func (agent *DocumentationAgent) analyzeController(file *ast.File, filePath string) {
	ast.Inspect(file, func(n ast.Node) bool {
		switch x := n.(type) {
		case *ast.FuncDecl:
			// æŸ¥æ‰¾ HTTP handler æ–¹æ³•
			if x.Recv != nil && x.Name.IsExported() {
				endpoint := agent.extractAPIEndpoint(x, filePath)
				if endpoint != nil {
					agent.analyzer.apiEndpoints = append(agent.analyzer.apiEndpoints, *endpoint)
				}
			}
		}
		return true
	})
}

// extractAPIEndpoint æå– API ç«¯é»è³‡è¨Š
func (agent *DocumentationAgent) extractAPIEndpoint(funcDecl *ast.FuncDecl, filePath string) *APIEndpoint {
	// ç°¡å–®çš„å•Ÿç™¼å¼æ–¹æ³•è­˜åˆ¥ HTTP handler
	funcName := funcDecl.Name.Name
	
	// å¸¸è¦‹çš„ HTTP handler æ¨¡å¼
	httpMethods := map[string]string{
		"Create": "POST",
		"Get":    "GET", 
		"Update": "PUT",
		"Delete": "DELETE",
		"List":   "GET",
	}

	var method string
	var path string
	var description string

	// æ ¹æ“šå‡½æ•¸åç¨±æ¨æ¸¬ HTTP æ–¹æ³•
	for prefix, httpMethod := range httpMethods {
		if strings.HasPrefix(funcName, prefix) {
			method = httpMethod
			break
		}
	}

	// æ¨æ¸¬ API è·¯å¾‘
	if strings.Contains(filePath, "wallet") {
		path = "/api/v1/wallets"
		description = "éŒ¢åŒ…ç›¸é—œ API"
	} else if strings.Contains(filePath, "category") {
		path = "/api/v1/categories"
		description = "åˆ†é¡ç›¸é—œ API"
	} else {
		path = "/api/v1/" + strings.ToLower(strings.TrimSuffix(funcName, "Handler"))
	}

	if method == "" {
		return nil
	}

	return &APIEndpoint{
		Method:      method,
		Path:        path,
		Handler:     funcName,
		Controller:  filepath.Base(filePath),
		Description: description,
		File:        filePath,
		Line:        agent.scanner.fileSet.Position(funcDecl.Pos()).Line,
		CreatedAt:   time.Now(),
	}
}

// analyzeDomainModel åˆ†æé ˜åŸŸæ¨¡å‹
func (agent *DocumentationAgent) analyzeDomainModel(file *ast.File, filePath string) {
	ast.Inspect(file, func(n ast.Node) bool {
		switch x := n.(type) {
		case *ast.TypeSpec:
			if structType, ok := x.Type.(*ast.StructType); ok {
				model := agent.extractDomainModel(x.Name.Name, structType, filePath)
				agent.analyzer.domainModels = append(agent.analyzer.domainModels, *model)
			}
		}
		return true
	})
}

// extractDomainModel æå–é ˜åŸŸæ¨¡å‹è³‡è¨Š
func (agent *DocumentationAgent) extractDomainModel(name string, structType *ast.StructType, filePath string) *DomainModel {
	model := &DomainModel{
		Name:      name,
		File:      filePath,
		CreatedAt: time.Now(),
	}

	// åˆ¤æ–·æ¨¡å‹é¡å‹
	if strings.Contains(strings.ToLower(name), "aggregate") || 
	   name == "Wallet" || name == "ExpenseCategory" || name == "IncomeCategory" {
		model.Type = "Aggregate"
	} else if strings.Contains(strings.ToLower(name), "record") {
		model.Type = "Entity"
	} else {
		model.Type = "ValueObject"
	}

	// æå–æ¬„ä½
	for _, field := range structType.Fields.List {
		for _, name := range field.Names {
			fieldInfo := ModelField{
				Name: name.Name,
				Type: agent.typeToString(field.Type),
			}
			
			if field.Tag != nil {
				fieldInfo.Tags = field.Tag.Value
			}
			
			model.Fields = append(model.Fields, fieldInfo)
		}
	}

	// ç”Ÿæˆæè¿°
	model.Description = fmt.Sprintf("%s é¡å‹çš„ %s", model.Type, name)

	return model
}

// analyzeUseCase åˆ†æä½¿ç”¨æ¡ˆä¾‹
func (agent *DocumentationAgent) analyzeUseCase(file *ast.File, filePath string) {
	ast.Inspect(file, func(n ast.Node) bool {
		switch x := n.(type) {
		case *ast.TypeSpec:
			if _, ok := x.Type.(*ast.StructType); ok && strings.HasSuffix(x.Name.Name, "Service") {
				useCase := &UseCase{
					Name:      x.Name.Name,
					Service:   x.Name.Name,
					File:      filePath,
					CreatedAt: time.Now(),
				}

				// åˆ¤æ–·é¡å‹
				if strings.Contains(filePath, "command") {
					useCase.Type = "Command"
					useCase.Description = "åŸ·è¡Œæ¥­å‹™æ“ä½œçš„å‘½ä»¤è™•ç†å™¨"
				} else {
					useCase.Type = "Query" 
					useCase.Description = "æŸ¥è©¢è³‡æ–™çš„æŸ¥è©¢è™•ç†å™¨"
				}

				agent.analyzer.useCases = append(agent.analyzer.useCases, *useCase)
			}
		}
		return true
	})
}

// analyzeDBSchema åˆ†æè³‡æ–™åº« Schema
func (agent *DocumentationAgent) analyzeDBSchema(filePath string) {
	content, err := os.ReadFile(filePath)
	if err != nil {
		return
	}

	// ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æŸ¥æ‰¾ CREATE TABLE èªå¥
	createTableRegex := regexp.MustCompile(`CREATE TABLE IF NOT EXISTS (\w+) \(`)
	matches := createTableRegex.FindAllStringSubmatch(string(content), -1)

	for _, match := range matches {
		if len(match) >= 2 {
			dbChange := DBChange{
				Type:      "CREATE_TABLE",
				Table:     match[1],
				Changes:   fmt.Sprintf("å»ºç«‹è³‡æ–™è¡¨ %s", match[1]),
				File:      filePath,
				CreatedAt: time.Now(),
			}
			agent.analyzer.dbChanges = append(agent.analyzer.dbChanges, dbChange)
		}
	}
}

// typeToString å°‡ AST é¡å‹è½‰æ›ç‚ºå­—ä¸²
func (agent *DocumentationAgent) typeToString(expr ast.Expr) string {
	switch t := expr.(type) {
	case *ast.Ident:
		return t.Name
	case *ast.StarExpr:
		return "*" + agent.typeToString(t.X)
	case *ast.ArrayType:
		return "[]" + agent.typeToString(t.Elt)
	case *ast.SelectorExpr:
		return agent.typeToString(t.X) + "." + t.Sel.Name
	default:
		return "interface{}"
	}
}

// generateSummary ç”Ÿæˆåˆ†ææ‘˜è¦
func (agent *DocumentationAgent) generateSummary(result *AnalysisResult) string {
	var summary strings.Builder
	
	summary.WriteString(fmt.Sprintf("ğŸ“Š å°ˆæ¡ˆåˆ†ææ‘˜è¦ (%s)\n\n", result.Timestamp.Format("2006-01-02 15:04:05")))
	
	if len(result.APIEndpoints) > 0 {
		summary.WriteString("ğŸŒ æ–°ç™¼ç¾çš„ API ç«¯é»:\n")
		for _, endpoint := range result.APIEndpoints {
			summary.WriteString(fmt.Sprintf("  - %s %s (%s)\n", endpoint.Method, endpoint.Path, endpoint.Handler))
		}
		summary.WriteString("\n")
	}

	if len(result.DomainModels) > 0 {
		summary.WriteString("ğŸ—ï¸ Domain Models:\n")
		for _, model := range result.DomainModels {
			summary.WriteString(fmt.Sprintf("  - %s (%s) - %d æ¬„ä½\n", model.Name, model.Type, len(model.Fields)))
		}
		summary.WriteString("\n")
	}

	if len(result.UseCases) > 0 {
		summary.WriteString("âš™ï¸ Use Cases:\n")
		for _, useCase := range result.UseCases {
			summary.WriteString(fmt.Sprintf("  - %s (%s)\n", useCase.Name, useCase.Type))
		}
		summary.WriteString("\n")
	}

	return summary.String()
}

// UpdateDocumentation æ›´æ–°æ–‡æª”
func (agent *DocumentationAgent) UpdateDocumentation(result *AnalysisResult) error {
	if !agent.config.UpdateDocs {
		return nil
	}

	fmt.Println("ğŸ“ é–‹å§‹æ›´æ–°æ–‡æª”...")

	// æ›´æ–° CLAUDE.md
	if err := agent.updateClaudeFile(result); err != nil {
		return fmt.Errorf("æ›´æ–° CLAUDE.md å¤±æ•—: %w", err)
	}

	// æ›´æ–° PROJECT-STATUS.md
	if err := agent.updateStatusFile(result); err != nil {
		return fmt.Errorf("æ›´æ–° PROJECT-STATUS.md å¤±æ•—: %w", err)
	}

	fmt.Println("âœ… æ–‡æª”æ›´æ–°å®Œæˆ!")
	return nil
}

// updateClaudeFile æ›´æ–° CLAUDE.md æª”æ¡ˆ
func (agent *DocumentationAgent) updateClaudeFile(result *AnalysisResult) error {
	// è®€å–ç¾æœ‰æª”æ¡ˆ
	content, err := os.ReadFile(agent.updater.claudeFile)
	if err != nil {
		return err
	}

	contentStr := string(content)
	
	// æ–°å¢æœ€è¿‘è®Šæ›´å€æ®µ
	changesSection := agent.generateChangesSection(result)
	
	// å°‹æ‰¾æ’å…¥é»æˆ–å»ºç«‹æ–°å€æ®µ
	if strings.Contains(contentStr, "## ğŸ“‹ æœ€è¿‘è®Šæ›´") {
		// æ›¿æ›ç¾æœ‰å€æ®µ
		re := regexp.MustCompile(`## ğŸ“‹ æœ€è¿‘è®Šæ›´.*?(?=## |\z)`)
		contentStr = re.ReplaceAllString(contentStr, changesSection)
	} else {
		// åœ¨é©ç•¶ä½ç½®æ’å…¥æ–°å€æ®µ
		insertPoint := strings.Index(contentStr, "## ğŸ”„ å¾…è¾¦äº‹é …")
		if insertPoint == -1 {
			contentStr += "\n\n" + changesSection
		} else {
			contentStr = contentStr[:insertPoint] + changesSection + "\n\n" + contentStr[insertPoint:]
		}
	}

	// å¯«å›æª”æ¡ˆ
	return os.WriteFile(agent.updater.claudeFile, []byte(contentStr), 0644)
}

// updateStatusFile æ›´æ–° PROJECT-STATUS.md æª”æ¡ˆ
func (agent *DocumentationAgent) updateStatusFile(result *AnalysisResult) error {
	// è®€å–ç¾æœ‰æª”æ¡ˆ
	content, err := os.ReadFile(agent.updater.statusFile)
	if err != nil {
		return err
	}

	contentStr := string(content)
	
	// æ›´æ–°æœ€å¾Œæ›´æ–°æ™‚é–“
	now := time.Now().Format("2006-01-02 15:04:05")
	re := regexp.MustCompile(`> æœ€å¾Œæ›´æ–°:.*`)
	contentStr = re.ReplaceAllString(contentStr, fmt.Sprintf("> æœ€å¾Œæ›´æ–°: %s", now))

	// å¯«å›æª”æ¡ˆ
	return os.WriteFile(agent.updater.statusFile, []byte(contentStr), 0644)
}

// generateChangesSection ç”Ÿæˆè®Šæ›´å€æ®µå…§å®¹
func (agent *DocumentationAgent) generateChangesSection(result *AnalysisResult) string {
	var section strings.Builder
	
	section.WriteString("## ğŸ“‹ æœ€è¿‘è®Šæ›´\n\n")
	section.WriteString(fmt.Sprintf("### %s\n", result.Timestamp.Format("2006-01-02")))
	
	if len(result.APIEndpoints) > 0 {
		section.WriteString("**API ç«¯é»**:\n")
		for _, endpoint := range result.APIEndpoints {
			section.WriteString(fmt.Sprintf("- âœ… %s `%s %s` - %s\n", endpoint.Handler, endpoint.Method, endpoint.Path, endpoint.Description))
		}
		section.WriteString("\n")
	}

	if len(result.DomainModels) > 0 {
		section.WriteString("**Domain Models**:\n")
		for _, model := range result.DomainModels {
			section.WriteString(fmt.Sprintf("- âœ… %s (%s) - %s\n", model.Name, model.Type, model.Description))
		}
		section.WriteString("\n")
	}

	if len(result.UseCases) > 0 {
		section.WriteString("**Use Cases**:\n")
		for _, useCase := range result.UseCases {
			section.WriteString(fmt.Sprintf("- âœ… %s (%s) - %s\n", useCase.Name, useCase.Type, useCase.Description))
		}
		section.WriteString("\n")
	}

	section.WriteString(fmt.Sprintf("**åˆ†ææ‘˜è¦**: æƒæäº† %d å€‹æª”æ¡ˆï¼Œç™¼ç¾ %d å€‹æ–°åŠŸèƒ½\n\n", 
		result.FilesScanned, len(result.APIEndpoints)+len(result.DomainModels)+len(result.UseCases)))

	return section.String()
}

// SaveAnalysisResult å„²å­˜åˆ†æçµæœ
func (agent *DocumentationAgent) SaveAnalysisResult(result *AnalysisResult) error {
	outputFile := filepath.Join(agent.projectRoot, "docs", "analysis-result.json")
	
	// ç¢ºä¿ç›®éŒ„å­˜åœ¨
	if err := os.MkdirAll(filepath.Dir(outputFile), 0755); err != nil {
		return err
	}

	data, err := json.MarshalIndent(result, "", "  ")
	if err != nil {
		return err
	}

	return os.WriteFile(outputFile, data, 0644)
}

// main å‡½æ•¸
func main() {
	if len(os.Args) < 2 {
		fmt.Println("ä½¿ç”¨æ–¹å¼: go run doc-agent.go <project-root>")
		os.Exit(1)
	}

	projectRoot := os.Args[1]
	agent := NewDocumentationAgent(projectRoot)

	// åŸ·è¡Œå°ˆæ¡ˆåˆ†æ
	result, err := agent.AnalyzeProject()
	if err != nil {
		fmt.Printf("âŒ åˆ†æå¤±æ•—: %v\n", err)
		os.Exit(1)
	}

	// å„²å­˜åˆ†æçµæœ
	if err := agent.SaveAnalysisResult(result); err != nil {
		fmt.Printf("âš ï¸ å„²å­˜åˆ†æçµæœå¤±æ•—: %v\n", err)
	}

	// æ›´æ–°æ–‡æª”
	if err := agent.UpdateDocumentation(result); err != nil {
		fmt.Printf("âŒ æ›´æ–°æ–‡æª”å¤±æ•—: %v\n", err)
		os.Exit(1)
	}

	// è¼¸å‡ºæ‘˜è¦
	fmt.Println("\n" + result.Summary)
}